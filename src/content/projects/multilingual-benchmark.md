---
title: 'MultiLingual Benchmark'
type: 'dataset'
status: 'active'
url: 'https://huggingface.co/datasets/example-lab/ml-bench'
repoUrl: 'https://github.com/example-lab/ml-bench'
team:
  - 'jane-smith'
  - 'maria-garcia'
tags:
  - 'Benchmark'
  - 'Multilingual'
  - 'Evaluation'
  - 'Dataset'
startDate: 2024-03-01
excerpt: 'A comprehensive benchmark for evaluating multilingual NLP models across 50+ languages.'
---

## Overview

MultiLingual Benchmark (ML-Bench) is a comprehensive evaluation suite for multilingual NLP models. It covers 50+ languages across diverse tasks including text classification, named entity recognition, question answering, and machine translation.

## Tasks

| Task                     | Languages | Metric           |
| ------------------------ | --------- | ---------------- |
| Text Classification      | 52        | F1 Score         |
| Named Entity Recognition | 40        | Entity F1        |
| Question Answering       | 35        | Exact Match / F1 |
| Machine Translation      | 28 pairs  | BLEU / COMET     |
| Summarization            | 20        | ROUGE-L          |

## Key Properties

- **Diverse language families**: Indo-European, Sino-Tibetan, Afro-Asiatic, Austronesian, and more
- **Low-resource coverage**: Includes 15 languages with limited digital resources
- **Cultural sensitivity**: Annotations reviewed by native speakers for cultural appropriateness
- **Regular updates**: New languages and tasks added quarterly

## Download

Available on [HuggingFace Datasets](https://huggingface.co/datasets/example-lab/ml-bench) and via our GitHub repository.
